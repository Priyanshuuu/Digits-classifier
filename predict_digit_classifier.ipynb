{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import sklearn\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCv =  4.0.0\n",
      "keras =  2.2.4\n",
      "Numpy =  1.16.4\n",
      "Sklearn =  0.20.0\n"
     ]
    }
   ],
   "source": [
    "print('OpenCv = ',cv2.__version__)\n",
    "print('keras = ',keras.__version__)\n",
    "print('Numpy = ',np.__version__)\n",
    "print('Sklearn = ',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 5*128)\n",
    "cap.set(4, 5*128)\n",
    "SIZE = 28\n",
    "img_width, img_height = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == \"channels first\":\n",
    "    input_shape = (1, img_width, img_height)\n",
    "    first_dim = 0\n",
    "    second_dim = 0\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 1)\n",
    "    first_dim = 0\n",
    "    second_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes labels on images\n",
    "def put_labels(frame, label, location = (20, 30)):\n",
    "    cv2.putText(frame, label, location, font, fontScale = 0.5, color = (255, 255, 0), thickness = 1, lineType = cv2.LINE_AA)\n",
    "    \n",
    "def extract_digits(frame, rect, pad = 10):\n",
    "    x, y, w, h = rect\n",
    "    crop_digit = final_img[y-pad:y+h+pad, x-pad:x+w+pad]\n",
    "    crop_digit = crop_digit / 255.0\n",
    "    \n",
    "    # Only looking at images that are somewhat big\n",
    "    if crop_digit.shape[0] >= 32 and crop_digit.shape[1] >= 32:\n",
    "        crop_digit = cv2.resize(crop_digit, (SIZE, SIZE))\n",
    "    else:\n",
    "        return\n",
    "    return crop_digit\n",
    "\n",
    "def img_to_mnist(frame, thresh = 90):\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    gray_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, blockSize = 321, C=28)\n",
    "    return gray_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    }
   ],
   "source": [
    "print(\"loading model\")\n",
    "model =  load_model(\"digit_classifier.mnist\")\n",
    "\n",
    "labels = dict(enumerate([\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    ret, frame = cap.read(0)\n",
    "    \n",
    "    final_img = img_to_mnist(frame)\n",
    "    image_shown = frame\n",
    "    \n",
    "    contours, _ = cv2.findContours(final_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    rects = [cv2.boundingRect(contour) for contour in contours]\n",
    "    rects = [rect for rect in rects if rect[2] >= 3 and rect[3] >= 8]\n",
    "    \n",
    "    #draw rectangles and predict\n",
    "    for rect in rects:\n",
    "        x, y, w, h = rect\n",
    "        \n",
    "        if i >= 0:\n",
    "            \n",
    "            mnist_frame = extract_digits(frame, rect, pad = 15)\n",
    "            \n",
    "            if mnist_frame is not None:\n",
    "                mnist_frame = np.expand_dims(mnist_frame, first_dim)\n",
    "                mnist_frame = np.expand_dims(mnist_frame, second_dim)\n",
    "                \n",
    "                class_prediction = model.predict_classes(mnist_frame, verbose = False)[0]\n",
    "                prediction = np.around(np.max(model.predict(mnist_frame, verbose = False)), 2)\n",
    "                label = str(prediction)\n",
    "                \n",
    "                cv2.rectangle(image_shown, (x - 15, y - 15), (x + 15 + w, y + 15 + h), color = (255, 255, 0))\n",
    "                \n",
    "                label = labels[class_prediction]\n",
    "                \n",
    "                put_labels(image_shown, label, location = (rect[0], rect[1]))\n",
    "                \n",
    "    cv2.imshow('frame', image_shown)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
